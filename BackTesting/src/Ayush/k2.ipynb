{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## kalman 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import os\n",
    "from numpy import dot\n",
    "from numpy import sum, tile, linalg, log, pi, exp\n",
    "from glob import glob\n",
    "from numpy.linalg import inv, det\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 : Basic Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-24 23:30:00</td>\n",
       "      <td>9557.66</td>\n",
       "      <td>9589.00</td>\n",
       "      <td>9556.00</td>\n",
       "      <td>9580.01</td>\n",
       "      <td>1927.603117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-25 00:30:00</td>\n",
       "      <td>9580.00</td>\n",
       "      <td>9583.80</td>\n",
       "      <td>9560.00</td>\n",
       "      <td>9581.76</td>\n",
       "      <td>1236.182213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-25 01:30:00</td>\n",
       "      <td>9581.76</td>\n",
       "      <td>9620.00</td>\n",
       "      <td>9567.23</td>\n",
       "      <td>9615.29</td>\n",
       "      <td>2119.244392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-25 02:30:00</td>\n",
       "      <td>9615.32</td>\n",
       "      <td>9637.00</td>\n",
       "      <td>9588.08</td>\n",
       "      <td>9591.55</td>\n",
       "      <td>2088.164018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-25 03:30:00</td>\n",
       "      <td>9591.55</td>\n",
       "      <td>9593.46</td>\n",
       "      <td>9522.00</td>\n",
       "      <td>9533.92</td>\n",
       "      <td>2069.404213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime     open     high      low    close       volume\n",
       "0  2020-07-24 23:30:00  9557.66  9589.00  9556.00  9580.01  1927.603117\n",
       "1  2020-07-25 00:30:00  9580.00  9583.80  9560.00  9581.76  1236.182213\n",
       "2  2020-07-25 01:30:00  9581.76  9620.00  9567.23  9615.29  2119.244392\n",
       "3  2020-07-25 02:30:00  9615.32  9637.00  9588.08  9591.55  2088.164018\n",
       "4  2020-07-25 03:30:00  9591.55  9593.46  9522.00  9533.92  2069.404213"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file(filename):\n",
    "    return pd.read_csv(filename)\n",
    "\n",
    "def get_data(timeframe):\n",
    "    return read_file(r\"C:\\Users\\ayush\\Desktop\\IITB\\ZeltaLabPS\\BackTesting\\data\\data\\btcusdt_\" + timeframe + \"_val.csv\")\n",
    "\n",
    "time_frame = \"1h\"\n",
    "df = get_data(time_frame)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_buckets(df, alphas, rets = ['ret_10', 'ret_30', 'ret_60', 'ret_300', 'tick_10'], aggfunc = ['mean', 'median', 'count'], buckets = 10):\n",
    "# def print_buckets(df, alphas, rets = ['ret_10', 'ret_30', 'iv_10'], aggfunc = ['mean', 'median', 'count']):\n",
    "# def print_buckets(df, alphas, rets = ['tick_10', 'tick_30', 'tick_60', 'tick_300'], aggfunc = ['mean', 'median', 'count']):\n",
    "# def print_buckets(df, alphas, rets = ['ret_60', 'ret_300', 'iv_60'], aggfunc = ['mean', 'median', 'count']):\n",
    "    for alpha in alphas:\n",
    "        msg = df.pivot_table(index = pd.qcut(df[alpha],buckets,duplicates='drop'), values=rets, aggfunc=aggfunc)\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_corrs(df, alphas, rets = ['ret_10', 'ret_30', 'ret_60', 'ret_300']):\n",
    "# def print_corrs(df, alphas, rets = ['ret_10', 'ret_30', 'iv_10']):\n",
    "# def print_corrs(df, alphas, rets = ['tick_10', 'tick_30', 'tick_60', 'tick_300']):\n",
    "# def print_corrs(df, alphas, rets = ['ret_60', 'ret_300', 'iv_60']):\n",
    "    msg = \"                                      \"\n",
    "    for ret in rets:\n",
    "        msg += f\"{ret:>8s}\"\n",
    "    print(msg)\n",
    "    for alpha in alphas:\n",
    "        msg = f\"{alpha:30s} corr -> \"\n",
    "        for ret in rets:\n",
    "            msg += f\"{df[alpha].corr(df[ret])*100:7.2f} \"\n",
    "        print(msg)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_smoothing(series, alpha):\n",
    "    result = [series[1]] # first value is same as series\n",
    "    for i in range(1, len(series)):\n",
    "        result.append(alpha * series[i] + (1 - alpha) * result[i-1])\n",
    "\n",
    "    return result\n",
    "# Assuming you have a dataframe called \"df\" with a column named \"close\"\n",
    "# alpha = 0.5\n",
    "# df['smoothed_close'] = exponential_smoothing(df['close'], alpha)\n",
    "def time_smooth(dataframe, col_name, halflife=15):\n",
    "    \"\"\"\n",
    "    This function will smooth the data\n",
    "    \"\"\"\n",
    "    hl = str(halflife)\n",
    "    string = str(col_name)\n",
    "    dataframe['datetime'] = pd.to_datetime(dataframe['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    dataframe[string] = dataframe['close'].ewm(halflife = hl,times=dataframe['datetime'], adjust = True).mean()\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['close_1'] = exponential_smoothing(df['close'], 0.99)\n",
    "df['close_999'] = exponential_smoothing(df['close'], 0.999)\n",
    "df['close_998'] = exponential_smoothing(df['close'], 0.998)\n",
    "df['close_995'] = exponential_smoothing(df['close'], 0.995)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['close_5'] = exponential_smoothing(df['close'], 0.95)\n",
    "df['close_10'] = exponential_smoothing(df['close'], 0.9)\n",
    "df['close_15'] = exponential_smoothing(df['close'], 0.85)\n",
    "df['close_30'] = exponential_smoothing(df['close'], 0.7)\n",
    "df['close_60'] = exponential_smoothing(df['close'], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['change_5'] = df['close'].rolling(window=5).mean().pct_change() * 1e4\n",
    "\n",
    "df['ret_5'] = df['close'].rolling(window=5).mean().pct_change() * 1e4\n",
    "df['ret_1'] = df['close'].rolling(window=1).mean().pct_change() * 1e4\n",
    "df['ret_10'] = df['close'].rolling(window=10).mean().pct_change() * 1e4\n",
    "df['ret_30'] = df['close'].rolling(window=30).mean().pct_change() * 1e4\n",
    "\n",
    "df['ret_5'] = df['ret_5'].shift(-5)\n",
    "df['ret_1'] = df['ret_1'].shift(-1)\n",
    "df['ret_10'] = df['ret_10'].shift(-10)\n",
    "df['ret_30'] = df['ret_30'].shift(-30)\n",
    "\n",
    "df.head(10)\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter:\n",
    "\n",
    "    def __init__(self, df, tbs, initial_state_mean, initial_state_covariance, X, P, A, Q, B, U, R):\n",
    "        \"\"\"\n",
    "        :param df: dataframe with the columns mentioned above\n",
    "        :param tbs: time between samples\n",
    "        :param initial_state_mean: initial state mean\n",
    "        :param initial_state_covariance: initial state covariance\n",
    "        :param observation_covariance: observation covariance\n",
    "        :param transition_covariance: transition covariance\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.tbs = tbs\n",
    "        self.initial_state_mean = initial_state_mean\n",
    "        self.initial_state_covariance = initial_state_covariance\n",
    "        self.initial_state_mean = initial_state_mean\n",
    "        self.initial_state_covariance = initial_state_covariance\n",
    "        self.counter = 0\n",
    "\n",
    "        self.X = X\n",
    "        self.P = P\n",
    "        self.A = A\n",
    "        self.Q = Q\n",
    "        self.B = B\n",
    "        self.U = U\n",
    "        self.R = R\n",
    "        self.H = np.eye(self.X.shape[0])\n",
    "        self.K = np.zeros((self.X.shape[0], self.X.shape[0]))   \n",
    "        self.Y = self.get_measurements()\n",
    "        self.LH = [0, 0]\n",
    "\n",
    "        # self.transition_matrices = transition_matrices\n",
    "        # self.transition_offsets = transition_offsets\n",
    "        # self.observation_matrices = observation_matrices\n",
    "        # self.observation_offsets = observation_offsets\n",
    "        # self.transition_covariance = transition_covariance\n",
    "        # self.observation_covariance = observation_covariance\n",
    "        \n",
    "\n",
    "    def kalman_init(self):\n",
    "        \"\"\"\n",
    "        This function will initialize the kalman filter\n",
    "        \"\"\"\n",
    "        # self.X = np.array([[0.0], [0.0], [0.0], [0.0], [0.0]])\n",
    "        # P is an array of 5x5 random values\n",
    "        self.P = np.zeros((5, 5))\n",
    "\n",
    "        # Fill the diagonal elements with random values between 0 and 1\n",
    "        P = np.eye(self.X.shape[0])\n",
    "\n",
    "        # Fill the off-diagonal elements with smaller random values\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                if i != j:\n",
    "                    self.P[i, j] = np.random.rand() * 0.1  # You can adjust the scale (0.1) as needed\n",
    "\n",
    "        self.A = np.array([[0.5, 1, -0.5, 0, 0.1], \n",
    "                    [0.5, 1, -0.5, 0, 0.05],\n",
    "                    [0.3, 1.5, -0.8, 0, 0.10],\n",
    "                    [0, 0, 0, 1, 0],\n",
    "                    [0, 0, 0, 0, 1]])\n",
    "        self.Q = np.eye(self.X.shape[0]) * 0.1\n",
    "        self.B = self.A * 0\n",
    "        self.U = self.X * 0\n",
    "        self.R = self.P\n",
    "        \n",
    "    def kf_predict(self):\n",
    "\n",
    "        r\"\"\"Calculate the mean and covariance of :math:`P(x_{t+1} | z_{0:t})`\n",
    "\n",
    "        Using the mean and covariance of :math:`P(x_t | z_{0:t})`, calculate the\n",
    "        mean and covariance of :math:`P(x_{t+1} | z_{0:t})`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        predicted_state_mean : [n_dim_state] array\n",
    "            mean of state at time t+1 given observations from times [0...t]\n",
    "        predicted_state_covariance : [n_dim_state, n_dim_state] array\n",
    "            covariance of state at time t+1 given observations from times\n",
    "            [0...t]\n",
    "        \"\"\"\n",
    "\n",
    "        self.X = dot(self.A, self.X) + dot(self.B, self.U)\n",
    "        self.P = dot(self.A, dot(self.P, self.A.T)) + self.Q\n",
    "\n",
    "        return(self.X, self.P) \n",
    "    \n",
    "\n",
    "\n",
    "    def kf_pdf(self, M, S):\n",
    "        if M.shape[1] == 1:\n",
    "            # Tile M to match the shape of X\n",
    "            DX = self.Y - np.tile(M, (1, self.Y.shape[1]))\n",
    "            # Compute the exponential term\n",
    "            E = 0.5 * np.sum(DX * (np.dot(inv(S), DX)), axis=0)\n",
    "            # Compute the probability density\n",
    "            E = E + 0.5 * M.shape[0] * log(2 * pi) + 0.5 * log(det(S))\n",
    "            # print(\"E:\", E)\n",
    "            P = m.exp(-E)\n",
    "        else:\n",
    "            # Case when both X and M have more than one column\n",
    "            DX = self.X - M\n",
    "            # Compute the exponential term\n",
    "            E = 0.5 * np.dot(DX.T, np.dot(inv(S), DX))\n",
    "            # Compute the probability density\n",
    "            E = E + 0.5 * M.shape[0] * log(2 * pi) + 0.5 * log(det(S))\n",
    "            P = np.exp(-E)\n",
    "        \n",
    "        # Return the first element of P and E if they are arrays\n",
    "        return (P[0] if isinstance(P, np.ndarray) else P, E[0] if isinstance(E, np.ndarray) else E)\n",
    "\n",
    "\n",
    "    def get_measurements(self):\n",
    "        halflives = [1, 995, 998, 999]\n",
    "        if self.counter in self.df.index:\n",
    "            self.Y = self.df.loc[self.counter, ['close', f'close_{halflives[0]}', f'close_{halflives[1]}', f'close_{halflives[2]}', f'close_{halflives[3]}']]\n",
    "            # self.Y = self.df.loc[self.counter, ['close', 'RSI', 'CCI', 'Momentum', 'volatility']]\n",
    "            self.Y = self.Y.values.reshape(5, 1)            \n",
    "            # print(\"self.Y ka shape:\", self.Y.shape)\n",
    "            # print(\"self.Y:\", self.Y)\n",
    "            # print(\"self.Y.shape:\", self.Y.shape)\n",
    "            return self.Y\n",
    "        else:\n",
    "            # Handle the case where self.counter is not in the DataFrame index\n",
    "            print(f\"Warning: Index {self.counter} not found in DataFrame.\")\n",
    "            self.flag = True\n",
    "            return None\n",
    "    \n",
    "    def kf_update(self):\n",
    "        IM = dot(self.H, self.X)\n",
    "        IS = self.R + dot(self.H, dot(self.P, self.H.T))\n",
    "        self.K = dot(self.P, dot(self.H.T, inv(IS)))\n",
    "        self.X = self.X + dot(self.K, (self.Y-IM))\n",
    "\n",
    "        # print(\"self.X:\", self.X)\n",
    "        # print(\"self.X.shape:\", self.X.shape)\n",
    "        # print(self.counter)\n",
    "        self.P = self.P - dot(self.K, dot(IS, self.K.T))\n",
    "        self.LH = self.kf_pdf(IM, IS)\n",
    "        return (self.X, self.P, self.K, self.LH)\n",
    "\n",
    "\n",
    "    def kalman_filter_run(self):\n",
    "        \"\"\"\n",
    "        :param x0: initial state mean\n",
    "        :param P0: initial state covariance\n",
    "        :param R: observation covariance\n",
    "        :param Q: transition covariance\n",
    "        :return: updated and predicted new values of x and P\n",
    "        \"\"\"\n",
    "        n = len(self.df)\n",
    "        print(\"n:\", n)\n",
    "        # To apply the kalman filter on each row of the dataframe\n",
    "\n",
    "        \n",
    "        while self.counter < n:\n",
    "            \n",
    "            self.Y = self.get_measurements()\n",
    "\n",
    "            if self.Y is None:\n",
    "                self.counter += 1\n",
    "                continue\n",
    "\n",
    "            self.X, self.P = self.kf_predict()\n",
    "            self.X, self.P, self.K, self.LH = self.kf_update()\n",
    "\n",
    "            self.df.loc[self.counter, 'kalman1'] = self.X[0]\n",
    "            self.df.loc[self.counter, 'kalman2'] = self.X[1]\n",
    "            self.df.loc[self.counter, 'kalman3'] = self.X[2]\n",
    "            self.df.loc[self.counter, 'kalman4'] = self.X[3]\n",
    "            self.df.loc[self.counter, 'kalman5'] = self.X[4]\n",
    "            self.df.loc[self.counter, 'kalman_conf'] = self.LH[0]\n",
    "            self.df.loc[self.counter, 'kalman_err'] = self.LH[1]\n",
    "\n",
    "            self.counter += 1\n",
    "\n",
    "\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_init():\n",
    "    \"\"\"\n",
    "    This function will initialize the kalman filter\n",
    "    \"\"\"\n",
    "    X = np.array([[0.0], [0.0], [0.0], [0.0], [0.0]])\n",
    "    # P is an array of 5x5 random values\n",
    "    feature_importances = np.array([4.40332102916679e-05, 3.566010909677725e-05, 3.093611319433873e-05, 0.9998415780908758, 4.779247654146511e-05])\n",
    "    normalized_importances = feature_importances / np.sum(feature_importances)\n",
    "\n",
    "\n",
    "    P = np.zeros((5, 5))\n",
    "\n",
    "    # Fill the diagonal elements with random values between 0 and 1\n",
    "    P = np.eye(X.shape[0])\n",
    "\n",
    "    # Fill the off-diagonal elements with smaller random values\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            if i != j:\n",
    "                P[i, j] = np.random.rand() * 0.1  # You can adjust the scale (0.1) as needed\n",
    "\n",
    "    # A = np.array([[0.5, 1, -0.5, 0, 0.1], \n",
    "    #               [0.5, 1, -0.5, 0, 0.05],\n",
    "    #               [0.3, 1.5, -0.8, 0, 0.10],\n",
    "    #               [0, 0, 0, 1, 0],\n",
    "    #               [0, 0, 0, 0, 1]])\n",
    "    \n",
    "    A = np.array([[feature_importances[3], feature_importances[0], feature_importances[1], feature_importances[2], feature_importances[4]], \n",
    "                  [0.0, 1.0, 0.0, 0, 0.0],\n",
    "                  [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "                  [0, 0, 0, 1, 0],\n",
    "                  [0, 0, 0, 0, 1]])\n",
    "    Q = np.eye(X.shape[0]) * 0.1\n",
    "    B = A * 0\n",
    "    U = X * 0\n",
    "    R = P\n",
    "    return X, P, A, Q, B, U, R\n",
    "\n",
    "\n",
    "X, P, A, Q, B, U, R = kalman_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_init_2():\n",
    "    \"\"\"\n",
    "    This function will initialize the kalman filter\n",
    "    \"\"\"\n",
    "    X = np.array([[0.0], [0.0], [0.0], [0.0], [0.0]])\n",
    "    # P is an array of 5x5 random values\n",
    "    feature_importances = np.array([4.40332102916679e-05, 3.566010909677725e-05, 3.093611319433873e-05, 0.9998415780908758, 4.779247654146511e-05])\n",
    "    normalized_importances = feature_importances / np.sum(feature_importances)\n",
    "\n",
    "\n",
    "    P = np.zeros((5, 5))\n",
    "\n",
    "    # Fill the diagonal elements with random values between 0 and 1\n",
    "    P = np.eye(X.shape[0])\n",
    "\n",
    "    # Fill the off-diagonal elements with smaller random values\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            if i != j:\n",
    "                P[i, j] = np.random.rand() * 0.1  # You can adjust the scale (0.1) as needed\n",
    "\n",
    "    # A = np.array([[0.5, 1, -0.5, 0, 0.1], \n",
    "    #               [0.5, 1, -0.5, 0, 0.05],\n",
    "    #               [0.3, 1.5, -0.8, 0, 0.10],\n",
    "    #               [0, 0, 0, 1, 0],\n",
    "    #               [0, 0, 0, 0, 1]])\n",
    "    \n",
    "    A = np.array([[0.4, 1.8, -1.2, 0, 0], \n",
    "                  [0.0, 1.0, 0.0, 0, 0.0],\n",
    "                  [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "                  [0, 0, 0, 1, 0],\n",
    "                  [0, 0, 0, 0, 1]])\n",
    "    \n",
    "    A = np.array([[1, 0, 0, 0, 0], \n",
    "                  [0.0, 1.0, 0.0, 0, 0.0],\n",
    "                  [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "                  [0, 0, 0, 1, 0],\n",
    "                  [0, 0, 0, 0, 1]])\n",
    "    Q = np.eye(X.shape[0]) * 0.1\n",
    "    B = A * 0\n",
    "    U = X * 0\n",
    "    R = P\n",
    "    return X, P, A, Q, B, U, R\n",
    "\n",
    "\n",
    "# X, P, A, Q, B, U, R = kalman_init_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KalmanFilter(df, 30, 0, 0, X, P, A, Q, B, U, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 7417\n"
     ]
    }
   ],
   "source": [
    "df = kf.kalman_filter_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['k_alpha1'] = df['kalman1'] - df['close']\n",
    "df['k_alpha2'] = df['kalman2'] - df['close']\n",
    "df['k_alpha3'] = df['kalman3'] - df['close']\n",
    "df['k_alpha4'] = df['kalman4'] - df['close']\n",
    "df['k_alpha5'] = df['kalman5'] - df['close']\n",
    "\n",
    "df['k_alpha1'] = pd.to_numeric(df['k_alpha1'], errors='coerce')\n",
    "df['k_alpha2'] = pd.to_numeric(df['k_alpha2'], errors='coerce')\n",
    "df['k_alpha3'] = pd.to_numeric(df['k_alpha3'], errors='coerce')\n",
    "df['k_alpha4'] = pd.to_numeric(df['k_alpha4'], errors='coerce')\n",
    "df['k_alpha5'] = pd.to_numeric(df['k_alpha5'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = ['ret_1', 'ret_5','ret_10']\n",
    "# aggfunc = ['mean', 'median', 'count']\n",
    "aggfunc = ['mean']\n",
    "alphas = ['k_alpha1', 'k_alpha2', 'k_alpha3', 'k_alpha4', 'k_alpha5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           mean                    \n",
      "                          ret_1    ret_10     ret_5\n",
      "k_alpha1                                           \n",
      "(-4587.015, -411.627] -0.775841  2.240344  1.006899\n",
      "(-411.627, -205.976]   4.775646  2.656551  3.219985\n",
      "(-205.976, -92.992]    0.222323  2.577467  1.621953\n",
      "(-92.992, -39.678]     3.568704  3.386525  2.056854\n",
      "(-39.678, -13.568]     3.094617  1.649724  1.696762\n",
      "(-13.568, 9.183]       3.263390  2.077629  2.022224\n",
      "(9.183, 45.785]        3.760109  2.044079  0.529323\n",
      "(45.785, 132.174]     -1.143231  1.999906  1.052640\n",
      "(132.174, 373.194]    -3.325708 -0.469933 -0.315309\n",
      "(373.194, 3732.257]    8.366570 -0.028180  5.571742\n",
      "                                    mean                    \n",
      "                                   ret_1    ret_10     ret_5\n",
      "k_alpha2                                                    \n",
      "(-4578.463000000001, -368.072] -1.531105  2.070715 -0.015491\n",
      "(-368.072, -178.947]            5.058008  2.902924  3.329171\n",
      "(-178.947, -79.658]             0.136915  2.081473  0.652271\n",
      "(-79.658, -34.21]               3.131593  3.313766  3.059519\n",
      "(-34.21, -11.71]                3.072091  2.295934  1.978924\n",
      "(-11.71, 8.587]                 4.826483  1.737928  1.384074\n",
      "(8.587, 41.576]                 3.534771  2.575578  1.430262\n",
      "(41.576, 121.082]              -2.813121  1.439874  0.954526\n",
      "(121.082, 323.528]              1.965672  0.194471  1.173428\n",
      "(323.528, 3426.546]             4.425013 -0.480431  4.514089\n",
      "                                     mean                    \n",
      "                                    ret_1    ret_10     ret_5\n",
      "k_alpha3                                                     \n",
      "(-4583.0830000000005, -411.052] -0.533648  2.201185  0.934511\n",
      "(-411.052, -205.882]             4.733817  2.833711  3.398620\n",
      "(-205.882, -92.786]             -0.188865  2.518669  1.569514\n",
      "(-92.786, -39.817]               4.056823  3.349260  2.102764\n",
      "(-39.817, -13.625]               2.895767  1.619036  1.604007\n",
      "(-13.625, 8.97]                  3.706492  2.205629  2.275357\n",
      "(8.97, 45.467]                   3.079803  1.767845  0.023829\n",
      "(45.467, 131.723]               -1.117594  2.095073  1.235837\n",
      "(131.723, 372.09]               -2.893263 -0.164336  0.216130\n",
      "(372.09, 3728.42]                8.067323 -0.291736  5.103021\n",
      "                           mean                    \n",
      "                          ret_1    ret_10     ret_5\n",
      "k_alpha4                                           \n",
      "(-4564.465, -362.655] -1.519225  2.150126  0.022007\n",
      "(-362.655, -176.262]   4.984654  2.955388  3.350338\n",
      "(-176.262, -77.767]    0.297818  1.874573  0.597826\n",
      "(-77.767, -33.501]     2.999634  3.218759  2.752314\n",
      "(-33.501, -11.487]     3.194917  2.410622  2.219217\n",
      "(-11.487, 8.483]       4.285317  1.803418  1.391311\n",
      "(8.483, 41.415]        4.015147  2.663739  1.519917\n",
      "(41.415, 118.555]     -3.160046  1.219027  0.877070\n",
      "(118.555, 319.23]      2.291753  0.201192  1.387311\n",
      "(319.23, 3386.534]     4.415371 -0.365099  4.343294\n",
      "                                     mean                    \n",
      "                                    ret_1    ret_10     ret_5\n",
      "k_alpha5                                                     \n",
      "(-4564.0740000000005, -358.786] -1.518993  2.104145 -0.055777\n",
      "(-358.786, -173.952]             4.681928  3.106956  3.160551\n",
      "(-173.952, -76.513]              1.141914  1.788030  1.021110\n",
      "(-76.513, -32.942]               2.123978  2.828853  2.262782\n",
      "(-32.942, -11.175]               3.102727  2.693921  2.457755\n",
      "(-11.175, 8.724]                 4.010097  1.768219  1.397696\n",
      "(8.724, 40.776]                  4.703174  2.750368  1.399271\n",
      "(40.776, 116.594]               -3.109027  1.411105  1.386173\n",
      "(116.594, 316.096]               2.207579  0.127704  1.153009\n",
      "(316.096, 3351.358]              4.462799 -0.447462  4.279300\n",
      "                                         ret_1   ret_5  ret_10\n",
      "k_alpha1                       corr ->    3.41    3.75   -1.57 \n",
      "k_alpha2                       corr ->    3.49    4.22   -1.23 \n",
      "k_alpha3                       corr ->    3.40    3.74   -1.56 \n",
      "k_alpha4                       corr ->    3.48    4.24   -1.19 \n",
      "k_alpha5                       corr ->    3.49    4.29   -1.14 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_buckets(df, alphas, rets, aggfunc)\n",
    "print_corrs(df, alphas, rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['flag1'] = np.nan\n",
    "df['flag1'] = np.where(df['k_alpha1'] > 300, 1, 0) \n",
    "\n",
    "n = len(df)\n",
    "compare = 0\n",
    "i = 0\n",
    "while i < n:\n",
    "    if df.loc[i, 'flag1'] == 1 and compare == 0:\n",
    "        df.loc[i, 'signal'] = 1\n",
    "        compare = 1\n",
    "        i = i + 1\n",
    "    elif df.loc[i, 'flag1'] == 1 and compare == 1:  \n",
    "        df.loc[i , 'signal'] = 0\n",
    "        i = i + 1\n",
    "    elif df.loc[i, 'flag1'] == 0 and compare == 1:\n",
    "        df.loc[i, 'signal'] = -1\n",
    "        compare = 0\n",
    "        i = i + 1\n",
    "    else:\n",
    "        df.loc[i, 'flag1'] = 0\n",
    "        i+=1\n",
    "\n",
    "df['signal'] = df['signal'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\ayush\\Desktop\\IITB\\ZeltaLabPS\\BackTesting\\src\\logs\\k2_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
